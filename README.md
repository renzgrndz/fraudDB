# ðŸ” Fraud Detection System
> A production-style fraud detection pipeline built with PostgreSQL, scikit-learn, and Streamlit.

---

## ðŸ“Œ Project Overview

This system detects fraudulent financial transactions using a full end-to-end data pipeline â€” from raw data ingestion to a live prediction interface. It was built as a final SQL project and extended into data engineering, machine learning, and a web application.

**Dataset:** PaySim â€” a synthetic mobile money transaction simulator (sampled to 100,000 rows)  
**Fraud Rate:** ~0.13% (highly imbalanced â€” this shapes every design decision)

---

## ðŸ—ï¸ Architecture

```
Raw CSV
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           PostgreSQL Database           â”‚
â”‚                                         â”‚
â”‚  staging.*       â† raw ingestion        â”‚
â”‚  core.*          â† normalized model     â”‚
â”‚  analytics.*     â† features & views     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ML Pipeline (Python)            â”‚
â”‚                                         â”‚
â”‚  Load features â†’ Train â†’ Evaluate       â”‚
â”‚  Save artifact (fraud_model.joblib)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Streamlit Application           â”‚
â”‚                                         â”‚
â”‚  Analytics Dashboard                    â”‚
â”‚  Model Performance                      â”‚
â”‚  Live Prediction Interface              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“ Project Structure

```
FDS_R1/
â”œâ”€â”€ artifacts/                  # Saved model files (auto-created)
â”‚   â”œâ”€â”€ fraud_model.joblib      # Best model artifact
â”‚   â”œâ”€â”€ lr_pipeline.joblib      # Logistic Regression pipeline
â”‚   â””â”€â”€ rf_pipeline.joblib      # Random Forest pipeline
â”œâ”€â”€ figures/                    # Evaluation plots (auto-created)
â”œâ”€â”€ app.py                      # Streamlit web application
â”œâ”€â”€ train_model.py              # ML training pipeline
â”œâ”€â”€ schema.sql                  # Database schema (3-layer)
â”œâ”€â”€ sample_data_load.sql        # ETL: staging â†’ core promotion
â”œâ”€â”€ queries.sql                 # Analytical & validation queries
â”œâ”€â”€ paysim_100k.csv             # Sampled dataset (100k rows)
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env                        # Database credentials
â””â”€â”€ README.md                   # This file
```

---

## âš™ï¸ Setup & Installation

### Prerequisites
- Python 3.10+
- PostgreSQL 14+
- pgAdmin 4
- PaySim dataset from [Kaggle](https://www.kaggle.com/datasets/ealaxi/paysim1)

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Configure Database Credentials

Create a `.env` file in your project root:

```
DB_URL=postgresql://postgres:yourpassword@127.0.0.1:5432/fraud_db
```

### 3. Create the Database

In pgAdmin Query Tool, connected to `fraud_db`, open and run `schema.sql`.

### 4. Prepare the Dataset

Sample the full PaySim CSV down to 100,000 rows:

```python
import pandas as pd
df = pd.read_csv("PS_20174392719_1491204439457_log.csv").sample(100_000, random_state=42)
df.to_csv("paysim_100k.csv", index=False)
```

### 5. Load Data into PostgreSQL

In pgAdmin: right-click `staging.raw_transactions` â†’ **Import/Export Data**
- Format: `csv`
- Header: **ON**
- File: path to `paysim_100k.csv`
- Columns: `step, type, amount, name_orig, old_balance_orig, new_balance_orig, name_dest, old_balance_dest, new_balance_dest, is_fraud, is_flagged_fraud`

Then promote staging â†’ core by running `sample_data_load.sql` in pgAdmin Query Tool.

### 6. Verify Data Load

```sql
SELECT COUNT(*) FROM staging.raw_transactions;   -- 100,000
SELECT COUNT(*) FROM core.accounts;              -- ~6,000
SELECT COUNT(*) FROM core.transactions;          -- 100,000
SELECT COUNT(*) FROM analytics.mv_ml_features;  -- 100,000
```

### 7. Train the Model

```bash
python train_model.py
```

Training produces ROC-AUC and PR-AUC scores for both models, a classification report, saved artifacts in `artifacts/`, and evaluation plots in `figures/`.

### 8. Launch the App

```bash
streamlit run app.py
```

Open your browser at `http://localhost:8501`

---

## ðŸ—„ï¸ Database Layer

### 3-Schema Design

| Schema | Purpose | Objects |
|---|---|---|
| `staging` | Raw CSV ingestion, no transformation | `raw_transactions` |
| `core` | Normalized 3NF model with constraints | `transactions`, `accounts`, `transaction_types` |
| `analytics` | Feature layer for ML and dashboards | `mv_ml_features`, `mv_sender_features`, views |

### Why Normalization?

The raw CSV stores "TRANSFER" as text in every row. The normalized model stores an integer ID instead, with a lookup table. This reduces storage, enforces consistency, and enables referential integrity â€” the database physically cannot contain a transaction pointing to a non-existent account.

### Constraints Applied

```sql
amount >= 0                          -- no negative transactions
account_type IN ('C', 'M')           -- only valid account types
sender_id â†’ core.accounts            -- foreign key
recipient_id â†’ core.accounts         -- foreign key
type_id â†’ core.transaction_types     -- foreign key
```

### Indexing Strategy

| Index | Columns | Purpose |
|---|---|---|
| `idx_txn_sender` | `sender_id` | Sender behavioral aggregations |
| `idx_txn_type_fraud` | `(type_id, is_fraud)` | Fraud-by-type dashboard queries |
| `idx_txn_sender_step` | `(sender_id, step)` | Temporal window functions |
| `idx_accounts_ref` | `account_ref` | ETL normalization lookups |

---

## ðŸ§® Feature Engineering

All features are computed in SQL using window functions and stored in `analytics.mv_ml_features`.

| Feature | Type | Fraud Signal |
|---|---|---|
| `sender_balance_drop` | Numeric | Large drop â†’ account draining |
| `dest_balance_mismatch` | Numeric | Amount â‰  balance change â†’ layering |
| `sender_drained` | Binary | Balance hits $0 â†’ full drain fraud |
| `dest_was_empty` | Binary | Recipient was empty â†’ mule account |
| `sender_amount_zscore` | Numeric | Unusual amount vs personal history |
| `sender_txns_same_step` | Numeric | High velocity â†’ automated fraud |
| `sender_unique_recipients` | Numeric | Fan-out pattern â†’ money scattering |
| `sender_historical_fraud_rate` | Numeric | Past fraud rate by this sender |

### Window Function Example

```sql
-- Z-score: how unusual is this amount for this specific sender?
(amount - AVG(amount) OVER (PARTITION BY sender_id))
/ NULLIF(STDDEV(amount) OVER (PARTITION BY sender_id), 0)
AS sender_amount_zscore
```

---

## ðŸ¤– Machine Learning

### Why Not Accuracy?

With a 0.13% fraud rate, a model predicting "legitimate" for every transaction achieves **99.87% accuracy** while catching zero fraud. Accuracy is meaningless on imbalanced data.

### Metrics We Use

| Metric | What It Measures |
|---|---|
| **Precision** | Of flagged fraud, how many were real? (false alarm cost) |
| **Recall** | Of real fraud, how many did we catch? (missed fraud cost) |
| **ROC-AUC** | Discrimination ability across all thresholds |
| **PR-AUC** | Primary metric â€” precision-recall tradeoff on positive class only |

### Class Imbalance Strategy

- **SMOTE** â€” generates synthetic fraud examples by interpolating between real ones
- **class_weight="balanced"** â€” increases training penalty for missing fraud
- **Stratified split** â€” preserves fraud rate in both train and test sets

### Models Trained

**Logistic Regression** â€” fast, interpretable, well-calibrated probabilities. Cannot capture nonlinear feature interactions. Best for explainability.

**Random Forest** â€” captures nonlinear interactions, robust to outliers, native feature importance. Best for raw performance.

The model with higher PR-AUC is automatically saved as the production artifact.

### Threshold Tuning

The model outputs a probability between 0 and 1. The decision threshold is adjustable:

- **Lower threshold** â†’ higher recall, more false alarms
- **Higher threshold** â†’ higher precision, more missed fraud

The Streamlit app includes a live slider to tune this based on business priorities.

---

## ðŸ“Š Streamlit Application

### Page 1 â€” Fraud Analytics Dashboard
- KPI metrics: total transactions, fraud count, fraud rate, fraud volume
- Fraud rate by transaction type (bar chart)
- Fraud trend over time (time series)
- Top risky senders ranking

### Page 2 â€” Model Performance
- ROC-AUC and PR-AUC scores
- Confusion matrix, ROC curve, Precision-Recall curve
- Feature importance chart

### Page 3 â€” Live Prediction
- Input form for transaction details and sender context
- Real-time fraud probability score
- Risk threshold slider
- Risk signal breakdown showing which factors triggered

### Caching Strategy

```python
@st.cache_resource        # DB engine + model â€” initialized once
@st.cache_data(ttl=300)   # Query results â€” refreshed every 5 minutes
```

---

## ðŸ”¬ Key SQL Queries

### Fraud Rate by Transaction Type
```sql
SELECT * FROM analytics.v_fraud_by_type;
```

### Fraud Trend Over Time
```sql
SELECT * FROM analytics.v_fraud_trend ORDER BY step;
```

### Top Risky Senders
```sql
SELECT * FROM analytics.v_risky_senders LIMIT 20;
```

### Anomalous Transactions (3+ std deviations above sender mean)
```sql
WITH sender_stats AS (
    SELECT sender_id, AVG(amount) AS mean, STDDEV(amount) AS std
    FROM core.transactions GROUP BY sender_id
)
SELECT t.transaction_id, a.account_ref, t.amount,
       ROUND((t.amount - ss.mean) / NULLIF(ss.std, 0), 2) AS z_score,
       t.is_fraud
FROM core.transactions t
JOIN sender_stats ss ON t.sender_id = ss.sender_id
JOIN core.accounts a ON t.sender_id = a.account_id
WHERE (t.amount - ss.mean) / NULLIF(ss.std, 0) > 3
ORDER BY z_score DESC;
```

---

## ðŸš€ Scaling Roadmap

| Phase | Stack |
|---|---|
| **Now (batch)** | PostgreSQL + scikit-learn + Streamlit |
| **Phase 2** | dbt for feature pipeline + MLflow for experiment tracking |
| **Phase 3** | Kafka ingestion + Flink for real-time feature computation |
| **Phase 4** | Feature store (Feast) + model registry + CI/CD deployment |

---

## ðŸ“¦ Dependencies

| Package | Purpose |
|---|---|
| `psycopg2-binary` | PostgreSQL driver |
| `sqlalchemy` | Database connection management |
| `pandas` | Data manipulation |
| `scikit-learn` | ML models and evaluation |
| `imbalanced-learn` | SMOTE for class imbalance |
| `joblib` | Model serialization |
| `matplotlib` | Visualization |
| `streamlit` | Web application |
| `python-dotenv` | Environment variable management |

---

## ðŸ‘¤ Author

**Renz Granadozo**  
Final Project â€” SQL & Data Engineering  
Built with PostgreSQL Â· scikit-learn Â· Streamlit
